## 7.2. Veri Ã–n Ä°ÅŸleme (Preprocessing)
**Ã–dev:** "Ham Veriden Saf Bilgiye: Veri HazÄ±rlama LaboratuvarÄ±"

### GÃ¶revler
1. **Ã–zellik Ã–lÃ§eklendirme (Feature Scaling):**
    - Elinizde "YaÅŸ" (20-70 arasÄ±) ve "YÄ±llÄ±k Gelir" (50.000 - 1.000.000 arasÄ±) sÃ¼tunlarÄ± var.
    - Bu iki veriyi aynÄ± Ã¶lÃ§eÄŸe getirmek iÃ§in **Standardization (Z-Score)** formÃ¼lÃ¼nÃ¼ kullanarak (Python veya elle) normalize edin. 
    - *FormÃ¼l:* $$z = \frac{x - \mu}{\sigma}$$
2. **Kategorik Veri Kodlama:**
    - "Åehir" adÄ±nda bir sÃ¼tununuz var ve deÄŸerler: `["Ä°stanbul", "Ankara", "Ä°zmir"]`.
    - Bu sÃ¼tunu modele sokabilmek iÃ§in **One-Hot Encoding** uygulandÄ±ÄŸÄ±nda nasÄ±l bir tablo oluÅŸacaÄŸÄ±nÄ± (0 ve 1'lerden oluÅŸan matris) Ã§izin veya yazÄ±n. Neden sadece 1, 2, 3 diyerek Label Encoding yapmadÄ±ÄŸÄ±mÄ±zÄ± tartÄ±ÅŸÄ±n.
3. **Ã–zellik SeÃ§imi ve Boyut Azaltma:**
    - 500 farklÄ± sÃ¼tunu (feature) olan bir veri setinde modelin Ã§ok yavaÅŸ Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± fark ettiniz.
    - Bilgi kaybÄ±nÄ± en aza indirerek sÃ¼tun sayÄ±sÄ±nÄ± azaltmak iÃ§in kullanÄ±lan temel kavramÄ±n (Ã¶rn: PCA) mantÄ±ÄŸÄ±nÄ± bir cÃ¼mleyle aÃ§Ä±klayÄ±n.




---

### ğŸ’¡ Kritik Notlar
* **Overfitting:** Modelin veriyi "ezberlemesi" demektir. GerÃ§ek hayatta (test verisinde) Ã§uvallar.
* **Scaling:** Makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n Ã§oÄŸu mesafe tabanlÄ±dÄ±r. Gelir gibi bÃ¼yÃ¼k sayÄ±lar, yaÅŸ gibi kÃ¼Ã§Ã¼k sayÄ±larÄ± "ezmesin" diye Ã¶lÃ§eklendirme hayati Ã¶nem taÅŸÄ±r.
